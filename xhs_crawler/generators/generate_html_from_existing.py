#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»å·²æœ‰çš„æœç´¢ç»“æœç”ŸæˆHTMLç½‘é¡µ
"""

import os
import json
import time
from typing import List, Dict, Any
from xhs_crawler.generators.html_generator import generate_html
from xhs_crawler.core.mcp_utils import load_json_data
from xhs_crawler.core.config import get_output_dir, get_html_file_path


class ExistingHtmlGenerator:
    """
    ä»å·²æœ‰æœç´¢ç»“æœç”ŸæˆHTMLçš„ç”Ÿæˆå™¨
    """
    
    def __init__(self, crawler_type: str = "simple"):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            crawler_type: çˆ¬è™«ç±»å‹
        """
        self.crawler_type = crawler_type
        self.output_dir = get_output_dir(crawler_type)
        self.html_file = get_html_file_path(crawler_type)
    
    def load_search_results(self) -> List[Dict[str, Any]]:
        """
        åŠ è½½æœç´¢ç»“æœ
        
        Returns:
            å¸–å­åˆ—è¡¨
        """
        # å°è¯•åŠ è½½å¤šç§å¯èƒ½çš„æœç´¢ç»“æœæ–‡ä»¶
        search_files = [
            os.path.join(self.output_dir, "åŸå§‹å“åº”.json"),
            os.path.join(self.output_dir, "åŸå§‹æœç´¢ç»“æœ.json"),
            os.path.join(self.output_dir, "all_search_results.json")
        ]
        
        for search_file in search_files:
            if os.path.exists(search_file):
                print(f"ğŸ” å°è¯•åŠ è½½æœç´¢ç»“æœæ–‡ä»¶: {search_file}")
                data = load_json_data(search_file)
                if data:
                    # å¤„ç†ä¸åŒæ ¼å¼çš„æœç´¢ç»“æœ
                    if "result" in data:
                        # æ ¼å¼1: {"result": {"code": 0, "data": {"notes": [...]}}}
                        search_result = data.get("result", {})
                        if search_result.get("code") == 0:
                            notes = search_result.get("data", {}).get("notes", [])
                            if notes:
                                print(f"âœ… æˆåŠŸåŠ è½½ {len(notes)} ç¯‡å¸–å­")
                                return notes
                    elif "notes" in data:
                        # æ ¼å¼2: {"notes": [...], "total_count": ...}
                        notes = data.get("notes", [])
                        print(f"âœ… æˆåŠŸåŠ è½½ {len(notes)} ç¯‡å¸–å­")
                        return notes
                    elif isinstance(data, list):
                        # æ ¼å¼3: [{"note_id": ...}, ...]
                        print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ç¯‡å¸–å­")
                        return data
        
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœç´¢ç»“æœæ–‡ä»¶")
        return []
    
    def run(self):
        """
        è¿è¡Œç”Ÿæˆå™¨
        """
        print("ğŸš€ å¯åŠ¨ä»ç°æœ‰æ•°æ®ç”ŸæˆHTML")
        
        # 1. åŠ è½½æœç´¢ç»“æœ
        notes = self.load_search_results()
        if not notes:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœç´¢ç»“æœ")
            return
        
        # 2. å‡†å¤‡å¸–å­æ•°æ®
        posts = []
        for note in notes:
            # æ„å»ºå¸–å­æ•°æ®ç»“æ„ï¼Œä¸å…¶ä»–çˆ¬è™«ä¿æŒä¸€è‡´
            post = {
                "basic_info": note,
                "detail": {}
            }
            posts.append(post)
        
        # 3. ç”ŸæˆHTMLç½‘é¡µ
        generate_html(posts, self.html_file, "å¤§æ¨¡å‹é¢è¯•ç»éªŒåˆ†äº«")
        
        print(f"ğŸ‰ HTMLç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸŒ HTMLç½‘é¡µ: {os.path.abspath(self.html_file)}")


def main():
    """
    ä¸»å‡½æ•°
    """
    generator = ExistingHtmlGenerator()
    generator.run()


if __name__ == "__main__":
    main()