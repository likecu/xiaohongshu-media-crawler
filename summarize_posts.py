#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨gemini_ocr.pyå¯¹å¸–å­å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œå¹¶ç”ŸæˆåŒ…å«æ€»ç»“çš„HTMLç½‘é¡µ
"""

import os
import json
import time
import subprocess
import requests
from typing import List, Dict, Any

# ç»“æœä¿å­˜ç›®å½•
OUTPUT_DIR = "å¤§æ¨¡å‹é¢è¯•å¸–å­"
DETAIL_DIR = os.path.join(OUTPUT_DIR, "è¯¦æƒ…")
SUMMARY_DIR = os.path.join(OUTPUT_DIR, "æ€»ç»“")
HTML_FILE = os.path.join(OUTPUT_DIR, "å¤§æ¨¡å‹é¢è¯•ç»éªŒåˆ†äº«_with_summary.html")

# OCRå·¥å…·è·¯å¾„
OCR_TOOL = "/Volumes/600g/app1/doubaoè·å–/python/gemini_ocr.py"

# å›¾ç‰‡OCRç»“æœç¼“å­˜
OCR_CACHE = {}
OCR_CACHE_FILE = os.path.join(SUMMARY_DIR, "ocr_cache.json")

def ensure_output_dirs():
    """
    ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼Œå¹¶åŠ è½½OCRç¼“å­˜
    """
    if not os.path.exists(SUMMARY_DIR):
        os.makedirs(SUMMARY_DIR)
        print(f"âœ… åˆ›å»ºæ€»ç»“ç›®å½•: {SUMMARY_DIR}")
    
    # åŠ è½½OCRç¼“å­˜
    global OCR_CACHE
    if os.path.exists(OCR_CACHE_FILE):
        try:
            with open(OCR_CACHE_FILE, "r", encoding="utf-8") as f:
                OCR_CACHE = json.load(f)
            print(f"âœ… åŠ è½½OCRç¼“å­˜æˆåŠŸï¼Œå…± {len(OCR_CACHE)} æ¡è®°å½•")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½OCRç¼“å­˜å¤±è´¥: {e}")
            OCR_CACHE = {}


def save_ocr_cache():
    """
    ä¿å­˜OCRç¼“å­˜åˆ°æœ¬åœ°
    """
    try:
        with open(OCR_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(OCR_CACHE, f, ensure_ascii=False, indent=2)
        print(f"âœ… OCRç¼“å­˜å·²ä¿å­˜ï¼Œå…± {len(OCR_CACHE)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ ä¿å­˜OCRç¼“å­˜å¤±è´¥: {e}")


def load_post_details() -> List[Dict[str, Any]]:
    """
    åŠ è½½æ‰€æœ‰å¸–å­è¯¦æƒ…
    
    Returns:
        å¸–å­è¯¦æƒ…åˆ—è¡¨
    """
    posts = []
    print(f"ğŸ“‚ å¼€å§‹åŠ è½½å¸–å­è¯¦æƒ…ï¼Œç›®å½•: {DETAIL_DIR}")
    
    if not os.path.exists(DETAIL_DIR):
        print(f"âŒ è¯¦æƒ…ç›®å½•ä¸å­˜åœ¨: {DETAIL_DIR}")
        return posts
    
    # è·å–æ‰€æœ‰è¯¦æƒ…æ–‡ä»¶
    detail_files = [f for f in os.listdir(DETAIL_DIR) if f.endswith("_detail.json")]
    print(f"ğŸ“ å‘ç° {len(detail_files)} ä¸ªè¯¦æƒ…æ–‡ä»¶")
    
    # éå†è¯¦æƒ…ç›®å½•
    for filename in detail_files:
        file_path = os.path.join(DETAIL_DIR, filename)
        print(f"ğŸ“„ æ­£åœ¨åŠ è½½: {filename}")
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                detail = json.load(f)
            posts.append({
                "filename": filename,
                "data": detail
            })
            print(f"âœ… åŠ è½½æˆåŠŸ: {filename}")
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {filename}, {e}")
        except UnicodeDecodeError as e:
            print(f"âŒ ç¼–ç é”™è¯¯: {filename}, {e}")
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {filename}, {e}")
    
    print(f"ğŸ“Š æˆåŠŸåŠ è½½ {len(posts)} ä¸ªå¸–å­è¯¦æƒ…ï¼Œè·³è¿‡ {len(detail_files) - len(posts)} ä¸ªæ–‡ä»¶")
    return posts

def download_image(image_url: str, save_path: str) -> bool:
    """
    ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°
    
    Args:
        image_url: å›¾ç‰‡URL
        save_path: ä¿å­˜è·¯å¾„
        
    Returns:
        æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    try:
        response = requests.get(image_url, timeout=30)
        response.raise_for_status()
        with open(save_path, 'wb') as f:
            f.write(response.content)
        return True
    except Exception as e:
        print(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {image_url}, é”™è¯¯: {e}")
        return False


def ocr_image(image_path: str, image_url: str = "") -> str:
    """
    å¯¹å›¾ç‰‡è¿›è¡ŒOCRè¯†åˆ«ï¼Œä½¿ç”¨å›¾ç‰‡URLä½œä¸ºç¼“å­˜é”®
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        image_url: å›¾ç‰‡URLï¼Œç”¨äºç¼“å­˜
        
    Returns:
        OCRè¯†åˆ«ç»“æœ
    """
    # ä¼˜å…ˆä½¿ç”¨å›¾ç‰‡URLä½œä¸ºç¼“å­˜é”®
    cache_key = image_url if image_url else image_path
    
    # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²æœ‰ç»“æœ
    if cache_key in OCR_CACHE:
        ocr_result = OCR_CACHE[cache_key]
        print(f"âœ… ä»ç¼“å­˜è·å–OCRç»“æœï¼Œé•¿åº¦: {len(ocr_result)} å­—ç¬¦")
        return ocr_result
    
    print(f"ğŸ” å¼€å§‹å¯¹å›¾ç‰‡è¿›è¡ŒOCRè¯†åˆ«: {image_path}")
    try:
        # ä½¿ç”¨gemini_ocr.pyè¿›è¡Œå›¾ç‰‡OCRè¯†åˆ«
        command = f"/Users/aaa/python-sdk/python3.13.2/bin/python {OCR_TOOL} {image_path} --question 'å›¾é‡Œæœ‰ä»€ä¹ˆå†…å®¹ï¼Ÿ'"
        result = subprocess.run(
            command, 
            shell=True, 
            capture_output=True, 
            text=True, 
            encoding="utf-8",
            timeout=60
        )
        
        if result.returncode != 0:
            print(f"âŒ å›¾ç‰‡OCRè¯†åˆ«å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"ğŸ’¬ é”™è¯¯è¾“å‡º: {result.stderr}")
            return ""
        
        # æå–OCRç»“æœ
        ocr_output = result.stdout.strip()
        if "=== å¤„ç†ç»“æœ ===" in ocr_output:
            result_part = ocr_output.split("=== å¤„ç†ç»“æœ ===")[1]
            if "å›ç­”: " in result_part:
                ocr_result = result_part.split("å›ç­”: ")[1].strip()
                print(f"âœ… å›¾ç‰‡OCRè¯†åˆ«æˆåŠŸï¼Œç»“æœé•¿åº¦: {len(ocr_result)} å­—ç¬¦")
                # å­˜å…¥ç¼“å­˜
                OCR_CACHE[cache_key] = ocr_result
                return ocr_result
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œè¿”å›å®Œæ•´è¾“å‡º
        print(f"âš ï¸  å›¾ç‰‡OCRç»“æœæ ¼å¼å¼‚å¸¸")
        # å­˜å…¥ç¼“å­˜
        OCR_CACHE[cache_key] = ocr_output
        return ocr_output
    except Exception as e:
        print(f"âŒ å›¾ç‰‡OCRè¯†åˆ«å¼‚å¸¸: {type(e).__name__}: {e}")
        return ""


def summarize_content(content: str, title: str, images: List[Dict[str, Any]] = None) -> str:
    """
    ä½¿ç”¨gemini_ocr.pyå¯¹å†…å®¹è¿›è¡Œæ€»ç»“ï¼ŒåŒ…æ‹¬å›¾ç‰‡OCRç»“æœ
    
    Args:
        content: å¸–å­å†…å®¹
        title: å¸–å­æ ‡é¢˜
        images: å›¾ç‰‡åˆ—è¡¨
        
    Returns:
        æ€»ç»“ç»“æœ
    """
    print(f"ğŸ” å¼€å§‹æ€»ç»“: '{title[:30]}...'")
    print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    
    try:
        # å¤„ç†å›¾ç‰‡ï¼Œè·å–OCRç»“æœ
        full_content = content
        if images and len(images) > 0:
            print(f"ğŸ“¸ å¼€å§‹å¤„ç† {len(images)} å¼ å›¾ç‰‡")
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜å›¾ç‰‡
            temp_dir = f"/tmp/xhs_post_images/{title[:20].replace(' ', '_')}"
            os.makedirs(temp_dir, exist_ok=True)
            
            for i, img in enumerate(images):
                img_url = img.get("url", "")
                if not img_url:
                    continue
                
                print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ç¬¬ {i+1}/{len(images)} å¼ å›¾ç‰‡: {img_url[:50]}...")
                
                # ä¸‹è½½å›¾ç‰‡
                img_save_path = os.path.join(temp_dir, f"image_{i+1}.jpg")
                if download_image(img_url, img_save_path):
                    # å¯¹å›¾ç‰‡è¿›è¡ŒOCRè¯†åˆ«ï¼Œä¼ é€’å›¾ç‰‡URLç”¨äºç¼“å­˜
                    ocr_result = ocr_image(img_save_path, img_url)
                    if ocr_result:
                        full_content += f"\n\n--- å›¾ç‰‡ {i+1} OCRç»“æœ ---\n{ocr_result}"
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(1)
        
        print(f"ğŸ“ å®Œæ•´å†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")
        
        # ç›´æ¥è°ƒç”¨gemini_ocr.pyè¿›è¡Œæ€»ç»“ï¼Œä¼ é€’é—®é¢˜å’Œå®Œæ•´å†…å®¹
        print(f"ğŸ”§ è°ƒç”¨gemini_ocr.pyå·¥å…·è¿›è¡Œæ€»ç»“...")
        question = f'è¯·æ€»ç»“è¿™ç¯‡å¤§æ¨¡å‹é¢è¯•ç»éªŒåˆ†äº«çš„ä¸»è¦å†…å®¹ï¼Œæå–å…³é”®é¢è¯•ç»éªŒã€æŠ€å·§å’Œå»ºè®®\n\n{full_content}'
        command = f"/Users/aaa/python-sdk/python3.13.2/bin/python {OCR_TOOL} --question \"{question}\""
        print(f"ğŸ’» æ‰§è¡Œå‘½ä»¤: {command[:100]}...")
        
        result = subprocess.run(
            command, 
            shell=True, 
            capture_output=True, 
            text=True, 
            encoding="utf-8",
            timeout=180  # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        )
        
        if result.returncode != 0:
            print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"ğŸ’¬ é”™è¯¯è¾“å‡º: {result.stderr}")
            return ""
        
        # æå–æ€»ç»“ç»“æœ
        summary_output = result.stdout.strip()
        # æ‰¾åˆ°å›ç­”éƒ¨åˆ†
        if "=== å¤„ç†ç»“æœ ===" in summary_output:
            result_part = summary_output.split("=== å¤„ç†ç»“æœ ===")[1]
            if "å›ç­”: " in result_part:
                summary = result_part.split("å›ç­”: ")[1].strip()
                print(f"âœ… æ€»ç»“æˆåŠŸï¼Œç»“æœé•¿åº¦: {len(summary)} å­—ç¬¦")
                return summary
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œè¿”å›å®Œæ•´è¾“å‡º
        print(f"âš ï¸  æœªæ‰¾åˆ°æ ‡å‡†å›ç­”æ ¼å¼ï¼Œè¿”å›å®Œæ•´è¾“å‡º")
        return summary_output
    except subprocess.TimeoutExpired:
        print(f"â±ï¸ æ€»ç»“è¶…æ—¶ï¼Œè¶…è¿‡120ç§’")
        return ""
    except Exception as e:
        print(f"âŒ æ€»ç»“å¼‚å¸¸: {type(e).__name__}: {e}")
        return ""

def is_llm_interview_question(summary: str) -> bool:
    """
    ä½¿ç”¨å¯¹è¯å·¥å…·åˆ¤æ–­æ€»ç»“æ˜¯å¦æ˜¯å¤§æ¨¡å‹ç›¸å…³çš„é¢è¯•é¢˜ç›®
    
    Args:
        summary: å¸–å­å†…å®¹æ€»ç»“
        
    Returns:
        æ˜¯å¦æ˜¯å¤§æ¨¡å‹ç›¸å…³çš„é¢è¯•é¢˜ç›®
    """
    print(f"ğŸ” å¼€å§‹åˆ¤æ–­æ˜¯å¦ä¸ºå¤§æ¨¡å‹ç›¸å…³é¢è¯•é¢˜")
    print(f"ğŸ“ æ€»ç»“é•¿åº¦: {len(summary)} å­—ç¬¦")
    
    try:
        # ä½¿ç”¨å¯¹è¯å·¥å…·æé—®
        question = f'è¯·åˆ¤æ–­ä»¥ä¸‹å†…å®¹æ˜¯å¦æ˜¯å¤§æ¨¡å‹ç›¸å…³çš„é¢è¯•é¢˜ç›®ï¼Œåªéœ€è¦å›ç­”"æ˜¯"æˆ–"å¦"\n\n{summary}'
        command = f"/Users/aaa/python-sdk/python3.13.2/bin/python {OCR_TOOL} --question \"{question}\""
        print(f"ğŸ’» æ‰§è¡Œå‘½ä»¤: {command[:100]}...")
        
        result = subprocess.run(
            command, 
            shell=True, 
            capture_output=True, 
            text=True, 
            encoding="utf-8",
            timeout=60
        )
        
        if result.returncode != 0:
            print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"ğŸ’¬ é”™è¯¯è¾“å‡º: {result.stderr}")
            return False
        
        # æå–åˆ¤æ–­ç»“æœ
        output = result.stdout.strip()
        print(f"ğŸ“‹ åˆ¤æ–­ç»“æœè¾“å‡º: {output}")
        
        # è§£æå›ç­”
        if "=== å¤„ç†ç»“æœ ===" in output:
            result_part = output.split("=== å¤„ç†ç»“æœ ===")[1]
            if "å›ç­”: " in result_part:
                answer = result_part.split("å›ç­”: ")[1].strip().lower()
                print(f"âœ… è§£æå›ç­”: {answer}")
                return "æ˜¯" in answer or "yes" in answer
        
        # ç›´æ¥æ£€æŸ¥è¾“å‡ºä¸­æ˜¯å¦åŒ…å«"æ˜¯"æˆ–"yes"
        answer = output.lower()
        print(f"âœ… ç›´æ¥è§£æå›ç­”: {answer}")
        return "æ˜¯" in answer or "yes" in answer
    except Exception as e:
        print(f"âŒ åˆ¤æ–­å¼‚å¸¸: {type(e).__name__}: {e}")
        return False

def save_summary(title: str, summary: str):
    """
    ä¿å­˜æ€»ç»“åˆ°æœ¬åœ°
    
    Args:
        title: å¸–å­æ ‡é¢˜
        summary: æ€»ç»“å†…å®¹
    """
    print(f"ğŸ’¾ å¼€å§‹ä¿å­˜æ€»ç»“: '{title[:30]}...'")
    clean_title = title.replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('<', '_').replace('>', '_').replace('|', '_').replace('"', '_')
    summary_file = os.path.join(SUMMARY_DIR, f"{clean_title}_summary.txt")
    print(f"ğŸ“„ ä¿å­˜è·¯å¾„: {summary_file}")
    
    try:
        with open(summary_file, "w", encoding="utf-8") as f:
            f.write(summary)
        print(f"âœ… æ€»ç»“å·²æˆåŠŸä¿å­˜: {summary_file}")
        print(f"ğŸ“Š æ€»ç»“é•¿åº¦: {len(summary)} å­—ç¬¦")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ€»ç»“å¤±è´¥: {e}")
        raise

def generate_html_with_summary(posts: List[Dict[str, Any]], summaries: Dict[str, str]):
    """
    ç”ŸæˆåŒ…å«æ€»ç»“çš„HTMLç½‘é¡µ
    
    Args:
        posts: å¸–å­åˆ—è¡¨
        summaries: å¸–å­æ€»ç»“å­—å…¸
    """
    print(f"ğŸ“ å¼€å§‹ç”ŸæˆåŒ…å«æ€»ç»“çš„HTMLç½‘é¡µ")
    print(f"ğŸ“Š æ€»å…±æœ‰ {len(posts)} ç¯‡å¸–å­éœ€è¦å¤„ç†")
    print(f"ğŸ“‹ å·²ç”Ÿæˆ {len(summaries)} ç¯‡å¸–å­çš„æ€»ç»“")
    
    # ç”Ÿæˆå¸–å­HTML
    posts_html = ""
    processed_count = 0
    summary_count = 0
    
    for i, post_item in enumerate(posts):
        print(f"ğŸ”§ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(posts)} ç¯‡å¸–å­")
        post = post_item.get("data", {})
        basic_info = post.get("basic_info", {})
        detail = post.get("detail", {})
        
        title = basic_info.get("title", "æ— æ ‡é¢˜")
        note_url = basic_info.get("note_url", "")
        user = basic_info.get("user", {})
        interact_info = basic_info.get("interact_info", {})
        
        print(f"ğŸ“„ å¸–å­æ ‡é¢˜: '{title[:30]}...'")
        
        # æå–å†…å®¹
        content = ""
        images = []
        
        if detail:
            if isinstance(detail, dict):
                notes_list = detail.get("notes", [])
                if notes_list:
                    first_note = notes_list[0]
                    content = first_note.get("desc", "")  # æ³¨æ„ï¼šå­—æ®µåæ˜¯descè€Œä¸æ˜¯content
                    image_list = first_note.get("imageList", [])  # æ³¨æ„ï¼šå­—æ®µåæ˜¯imageListè€Œä¸æ˜¯images
                    # æå–å›¾ç‰‡URL
                    for img in image_list:
                        # ä»infoListæˆ–urlDefaultè·å–å›¾ç‰‡URL
                        if "infoList" in img and img["infoList"]:
                            # ä½¿ç”¨infoListä¸­çš„ç¬¬ä¸€ä¸ªURL
                            images.append({"url": img["infoList"][0].get("url", "")})
                        elif "urlDefault" in img:
                            # ä½¿ç”¨urlDefault
                            images.append({"url": img["urlDefault"]})
        
        print(f"ğŸ“ å¸–å­å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(images)}")
        
        # è·å–æ€»ç»“
        summary = summaries.get(title, "")
        if summary:
            summary_count += 1
            print(f"ğŸ“‹ åŒ…å«æ€»ç»“ï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
        else:
            print(f"âš ï¸ æ— æ€»ç»“å†…å®¹")
        
        # ç”Ÿæˆå›¾ç‰‡HTML
        images_html = ""
        for img in images:
            img_url = img.get("url", "")
            if img_url:
                images_html += f"<img src='{img_url}' alt='å¸–å­å›¾ç‰‡' style='width: 100%; height: auto; border-radius: 4px; margin: 5px;'>"
        
        # ç”Ÿæˆå•ä¸ªå¸–å­HTML - ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æ‹¼æ¥
        post_html = ""
        post_html += f"<div style='background-color: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1); margin-bottom: 30px; padding: 20px; transition: transform 0.3s ease, box-shadow 0.3s ease;'>"
        post_html += f"<div>"
        post_html += f"<h2 style='font-size: 24px; color: #2c3e50; margin-bottom: 10px;'><a href='{note_url}' target='_blank' style='color: #2c3e50; text-decoration: none;'>{i+1}. {title}</a></h2>"
        post_html += f"<div style='display: flex; align-items: center; color: #7f8c8d; font-size: 14px;'>"
        post_html += f"<div style='display: flex; align-items: center; margin-right: 20px;'>"
        post_html += f"<img src='{user.get('avatar', '')}' alt='ç”¨æˆ·å¤´åƒ' style='width: 30px; height: 30px; border-radius: 50%; margin-right: 10px;'>"
        post_html += f"<span style='font-weight: 500; margin-right: 10px;'>{user.get('nickname', 'åŒ¿åç”¨æˆ·')}</span>"
        post_html += f"</div>"
        post_html += f"<div style='display: flex; gap: 20px;'>"
        post_html += f"<div style='display: flex; align-items: center; gap: 5px;'>ğŸ‘ {interact_info.get('liked_count', 0)}</div>"
        post_html += f"<div style='display: flex; align-items: center; gap: 5px;'>ğŸ’¾ {interact_info.get('collected_count', 0)}</div>"
        post_html += f"<div style='display: flex; align-items: center; gap: 5px;'>ğŸ’¬ {interact_info.get('comment_count', 0)}</div>"
        post_html += f"<div style='display: flex; align-items: center; gap: 5px;'>ğŸ”— {interact_info.get('share_count', 0)}</div>"
        post_html += f"</div>"
        post_html += f"</div>"
        post_html += f"</div>"
        
        if content:
            post_html += f"<div style='margin: 20px 0; line-height: 1.8; color: #555;'>{content}</div>"
        
        if images_html:
            post_html += f"<div style='margin: 20px 0;'>{images_html}</div>"
        
        if summary:
            post_html += f"<div style='background-color: #e8f4f8; border-left: 4px solid #3498db; padding: 15px; margin: 20px 0; border-radius: 4px;'>"
            post_html += f"<h3 style='color: #2c3e50; margin-bottom: 10px;'>ğŸ“ å†…å®¹æ€»ç»“</h3>"
            post_html += f"<div style='line-height: 1.6; color: #333;'>{summary}</div>"
            post_html += f"</div>"
        
        post_html += f"</div>"
        
        posts_html += post_html
        processed_count += 1
        print(f"âœ… ç¬¬ {i+1} ç¯‡å¸–å­å¤„ç†å®Œæˆ")
    
    print(f"ğŸ“‹ å¸–å­å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {processed_count} ç¯‡ï¼Œå…¶ä¸­ {summary_count} ç¯‡åŒ…å«æ€»ç»“")
    
    # ç”Ÿæˆå®Œæ•´HTML
    print(f"ğŸ”¨ å¼€å§‹ç”Ÿæˆå®Œæ•´çš„HTMLå†…å®¹")
    html_content = f"<!DOCTYPE html>\n"
    html_content += f"<html lang='zh-CN'>\n"
    html_content += f"<head>\n"
    html_content += f"<meta charset='UTF-8'>\n"
    html_content += f"<meta name='viewport' content='width=device-width, initial-scale=1.0'>\n"
    html_content += f"<title>å¤§æ¨¡å‹é¢è¯•ç»éªŒåˆ†äº« - å¸¦æ€»ç»“</title>\n"
    html_content += f"<style>\n"
    html_content += f"* {{ margin: 0; padding: 0; box-sizing: border-box; }}\n"
    html_content += f"body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; line-height: 1.6; color: #333; background-color: #f5f5f5; }}\n"
    html_content += f".container {{ max-width: 1200px; margin: 0 auto; padding: 20px; }}\n"
    html_content += f"h1 {{ text-align: center; color: #2c3e50; margin-bottom: 30px; padding: 20px 0; border-bottom: 2px solid #3498db; }}\n"
    html_content += f".footer {{ text-align: center; color: #7f8c8d; padding: 20px 0; margin-top: 50px; border-top: 1px solid #e0e0e0; }}\n"
    html_content += f"</style>\n"
    html_content += f"</head>\n"
    html_content += f"<body>\n"
    html_content += f"<div class='container'>\n"
    html_content += f"<h1>å¤§æ¨¡å‹é¢è¯•ç»éªŒåˆ†äº« - å¸¦å†…å®¹æ€»ç»“</h1>\n"
    html_content += f"<!-- å¸–å­åˆ—è¡¨ -->\n"
    html_content += f"{posts_html}\n"
    html_content += f"<div class='footer'>\n"
    html_content += f"<p>ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>\n"
    html_content += f"<p>å…± {len(posts)} ç¯‡å¸–å­</p>\n"
    html_content += f"</div>\n"
    html_content += f"</div>\n"
    html_content += f"</body>\n"
    html_content += f"</html>\n"
    
    print(f"ğŸ“„ HTMLå†…å®¹ç”Ÿæˆå®Œæˆï¼Œæ€»é•¿åº¦: {len(html_content)} å­—ç¬¦")
    
    # ä¿å­˜HTMLæ–‡ä»¶
    print(f"ğŸ’¾ å¼€å§‹ä¿å­˜HTMLæ–‡ä»¶: {HTML_FILE}")
    try:
        with open(HTML_FILE, "w", encoding="utf-8") as f:
            f.write(html_content)
        print(f"âœ… HTMLç½‘é¡µå·²æˆåŠŸç”Ÿæˆ: {HTML_FILE}")
        print(f"ğŸ“Š å…±ç”Ÿæˆ {processed_count} ç¯‡å¸–å­ï¼Œå…¶ä¸­ {summary_count} ç¯‡åŒ…å«æ€»ç»“")
    except Exception as e:
        print(f"âŒ ä¿å­˜HTMLæ–‡ä»¶å¤±è´¥: {e}")
        raise

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ å¯åŠ¨å¸–å­æ€»ç»“ç¨‹åº")
    start_time = time.time()
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    ensure_output_dirs()
    
    # 1. åŠ è½½å¸–å­è¯¦æƒ…
    posts = load_post_details()
    if not posts:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¸–å­è¯¦æƒ…")
        return
    
    print(f"âœ… åŠ è½½äº† {len(posts)} ç¯‡å¸–å­è¯¦æƒ…")
    
    # 2. å¯¹æ¯ä¸ªå¸–å­è¿›è¡Œæ€»ç»“å’Œåˆ¤æ–­
    valid_posts = []  # ä¿å­˜ç¬¦åˆæ¡ä»¶çš„å¸–å­
    summaries = {}
    print(f"ğŸ“ å¼€å§‹å¯¹å¸–å­è¿›è¡Œæ€»ç»“")
    
    for i, post_item in enumerate(posts):
        print(f"ğŸ”§ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(posts)} ç¯‡å¸–å­")
        post = post_item.get("data", {})
        basic_info = post.get("basic_info", {})
        detail = post.get("detail", {})
        filename = post_item.get("filename", "")
        
        title = basic_info.get("title", "æ— æ ‡é¢˜")
        
        # æå–å†…å®¹å’Œå›¾ç‰‡
        content = ""
        images = []
        if detail:
            if isinstance(detail, dict):
                notes_list = detail.get("notes", [])
                if notes_list:
                    first_note = notes_list[0]
                    content = first_note.get("desc", "")  # æ³¨æ„ï¼šå­—æ®µåæ˜¯descè€Œä¸æ˜¯content
                    
                    # æå–å›¾ç‰‡URL
                    image_list = first_note.get("imageList", [])  # æ³¨æ„ï¼šå­—æ®µåæ˜¯imageListè€Œä¸æ˜¯images
                    for img in image_list:
                        img_url = ""
                        if "infoList" in img and img["infoList"]:
                            # ä½¿ç”¨infoListä¸­çš„ç¬¬ä¸€ä¸ªURL
                            img_url = img["infoList"][0].get("url", "")
                        elif "urlDefault" in img:
                            # ä½¿ç”¨urlDefault
                            img_url = img["urlDefault"]
                        elif "url" in img:
                            # ä½¿ç”¨urlå­—æ®µ
                            img_url = img["url"]
                        
                        if img_url:
                            images.append({"url": img_url})
        
        # åˆå¹¶å†…å®¹ç”¨äºåˆ¤æ–­
        combined_content = content
        for img in images:
            combined_content += f"\nå›¾ç‰‡URL: {img.get('url', '')}"
        
        if combined_content:
            print(f"ğŸ“„ å¸–å­æ ‡é¢˜: '{title[:30]}...'")
            print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(combined_content)} å­—ç¬¦")
            print(f"ğŸ“¸ å›¾ç‰‡æ•°é‡: {len(images)} å¼ ")
            
            # ç›´æ¥åˆ¤æ–­æ˜¯å¦ä¸ºå¤§æ¨¡å‹ç›¸å…³é¢è¯•é¢˜ï¼Œä¸éœ€è¦å…ˆæ€»ç»“
            is_llm_interview = is_llm_interview_question(combined_content)
            print(f"ğŸ“‹ æ˜¯å¤§æ¨¡å‹ç›¸å…³é¢è¯•é¢˜: {is_llm_interview}")
            
            if is_llm_interview:
                # åªæœ‰ç¬¦åˆæ¡ä»¶çš„å¸–å­æ‰è¿›è¡Œæ€»ç»“
                summary = summarize_content(content, title, images)
                if summary:
                    summaries[title] = summary
                    save_summary(title, summary)
                    valid_posts.append(post_item)  # åªä¿ç•™ç¬¦åˆæ¡ä»¶çš„å¸–å­
                    print(f"âœ… å¸–å­ç¬¦åˆæ¡ä»¶ï¼Œå·²æ·»åŠ åˆ°æœ‰æ•ˆåˆ—è¡¨")
                else:
                    print(f"âŒ æ€»ç»“å¤±è´¥ï¼Œè·³è¿‡æ­¤å¸–å­")
            else:
                print(f"âŒ å¸–å­ä¸ç¬¦åˆæ¡ä»¶ï¼Œå‡†å¤‡åˆ é™¤")
                # åˆ é™¤ä¸ç¬¦åˆæ¡ä»¶çš„å¸–å­è¯¦æƒ…æ–‡ä»¶
                detail_file_path = os.path.join(DETAIL_DIR, filename)
                if os.path.exists(detail_file_path):
                    os.remove(detail_file_path)
                    print(f"âœ… å·²åˆ é™¤ä¸ç¬¦åˆæ¡ä»¶çš„å¸–å­æ–‡ä»¶: {detail_file_path}")
        else:
            print(f"âš ï¸  å¸–å­å†…å®¹ä¸ºç©ºï¼Œå‡†å¤‡åˆ é™¤")
            # åˆ é™¤å†…å®¹ä¸ºç©ºçš„å¸–å­è¯¦æƒ…æ–‡ä»¶
            detail_file_path = os.path.join(DETAIL_DIR, filename)
            if os.path.exists(detail_file_path):
                os.remove(detail_file_path)
                print(f"âœ… å·²åˆ é™¤å†…å®¹ä¸ºç©ºçš„å¸–å­æ–‡ä»¶: {detail_file_path}")
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(2)
    
    print(f"âœ… å·²æ€»ç»“ {len(summaries)} ç¯‡ç¬¦åˆæ¡ä»¶çš„å¸–å­")
    
    # 3. ç”ŸæˆåŒ…å«æ€»ç»“çš„HTMLç½‘é¡µ
    if valid_posts:
        print(f"ğŸ“ å¼€å§‹ç”ŸæˆåŒ…å«æ€»ç»“çš„HTMLç½‘é¡µ")
        generate_html_with_summary(valid_posts, summaries)
    else:
        print(f"âš ï¸  æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å¸–å­ï¼Œè·³è¿‡HTMLç”Ÿæˆ")
    
    # ä¿å­˜OCRç¼“å­˜
    save_ocr_cache()
    
    end_time = time.time()
    print(f"ğŸ‰ å¸–å­æ€»ç»“å®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f} ç§’")
    print(f"ğŸ“ æ€»ç»“ä¿å­˜ç›®å½•: {os.path.abspath(SUMMARY_DIR)}")
    if valid_posts:
        print(f"ğŸŒ åŒ…å«æ€»ç»“çš„HTMLç½‘é¡µ: {os.path.abspath(HTML_FILE)}")
    print(f"ğŸ“Š å…±å¤„ç† {len(posts)} ç¯‡å¸–å­ï¼Œå…¶ä¸­ {len(valid_posts)} ç¯‡ç¬¦åˆå¤§æ¨¡å‹ç›¸å…³é¢è¯•é¢˜æ¡ä»¶")

if __name__ == "__main__":
    main()